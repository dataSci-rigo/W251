{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tf_trt_models.classification import download_classification_checkpoint\n",
    "\n",
    "checkpoint_path = download_classification_checkpoint('inception_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./inception_v2/inception_v2.ckpt\n",
      "WARNING:tensorflow:From /notebooks/tf_trt_models/tf_trt_models/classification.py:215: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 277 variables.\n",
      "INFO:tensorflow:Converted 277 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from tf_trt_models.classification import build_classification_graph\n",
    "\n",
    "frozen_graph, input_names, output_names = build_classification_graph(\n",
    "    model='inception_v2',\n",
    "    checkpoint=checkpoint_path,\n",
    "    num_classes=1001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running against TensorRT version 5.0.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.tensorrt as trt\n",
    "\n",
    "trt_graph = trt.create_inference_graph(\n",
    "    input_graph_def=frozen_graph,\n",
    "    outputs=output_names,\n",
    "    max_batch_size=1,\n",
    "    max_workspace_size_bytes=1 << 25,\n",
    "    precision_mode='FP16',\n",
    "    minimum_segment_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "\n",
    "tf_sess = tf.Session(config=tf_config)\n",
    "\n",
    "tf.import_graph_def(trt_graph, name='')\n",
    "\n",
    "tf_input = tf_sess.graph.get_tensor_by_name(input_names[0] + ':0')\n",
    "tf_output = tf_sess.graph.get_tensor_by_name(output_names[0] + ':0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'inception_v1'\n",
    "CHECKPOINT_PATH = 'inception_v1.ckpt'\n",
    "NUM_CLASSES = 1001\n",
    "LABELS_PATH = './data/imagenet_labels_%d.txt' % NUM_CLASSES\n",
    "IMAGE_PATH = 'examples/classification/data/dog-yawning.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import urllib\n",
    "image = Image.open(IMAGE_PATH)\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)\n",
    "\n",
    "width = int(tf_input.shape.as_list()[1])\n",
    "height = int(tf_input.shape.as_list()[2])\n",
    "\n",
    "import numpy as np\n",
    "image = np.array(image.resize((width, height)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf_sess.run(tf_output, feed_dict={\n",
    "    tf_input: image[None, ...]\n",
    "})\n",
    "\n",
    "scores = output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.371518) cocker spaniel, English cocker spaniel, cocker\n",
      "\n",
      "(0.237076) golden retriever\n",
      "\n",
      "(0.025085) Blenheim spaniel\n",
      "\n",
      "(0.020635) clumber, clumber spaniel\n",
      "\n",
      "(0.013962) Labrador retriever\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "LABELS_PATH = 'examples/classification/data/imagenet_labels_%d.txt' % NUM_CLASSES\n",
    "with open(LABELS_PATH, 'r') as f:\n",
    "    labels = f.readlines()\n",
    "\n",
    "top5_idx = scores.argsort()[::-1][0:5]\n",
    "\n",
    "for i in top5_idx:\n",
    "    print('(%3f) %s' % (scores[i], labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-26 06:22:23--  https://cdn.vox-cdn.com/thumbor/rC0mlBATZdoDW1tEa44P6431sGc=/0x0:3683x2455/1200x800/filters:focal(1623x234:2211x822)/cdn.vox-cdn.com/uploads/chorus_image/image/63273148/usa_today_12005182.0.jpg\n",
      "Resolving cdn.vox-cdn.com (cdn.vox-cdn.com)... 151.101.188.124\n",
      "Connecting to cdn.vox-cdn.com (cdn.vox-cdn.com)|151.101.188.124|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 116962 (114K) [image/jpeg]\n",
      "Saving to: 'examples/classification/data/warriors.jpg'\n",
      "\n",
      "examples/classifica 100%[===================>] 114.22K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2019-06-26 06:22:23 (1.08 MB/s) - 'examples/classification/data/warriors.jpg' saved [116962/116962]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IMAGE_PATH = 'examples/classification/data/warriors.jpg'\n",
    "!wget 'https://cdn.vox-cdn.com/thumbor/rC0mlBATZdoDW1tEa44P6431sGc=/0x0:3683x2455/1200x800/filters:focal(1623x234:2211x822)/cdn.vox-cdn.com/uploads/chorus_image/image/63273148/usa_today_12005182.0.jpg' -O {IMAGE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Agg')\n",
    "image = Image.open(IMAGE_PATH)\n",
    "\n",
    "plt.imshow(image)\n",
    "width = int(tf_input.shape.as_list()[1])\n",
    "height = int(tf_input.shape.as_list()[2])\n",
    "\n",
    "\n",
    "image = np.array(image.resize((width, height)))\n",
    "#image_resized = np.array(image.resize((300, 300)))\n",
    "image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf_sess.run(tf_output, feed_dict={\n",
    "    tf_input: image[None, ...]\n",
    "})\n",
    "\n",
    "scores = output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.802698) basketball\n",
      "\n",
      "(0.010466) volleyball\n",
      "\n",
      "(0.007480) parallel bars, bars\n",
      "\n",
      "(0.006784) balance beam, beam\n",
      "\n",
      "(0.005963) horizontal bar, high bar\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LABELS_PATH = 'examples/classification/data/imagenet_labels_%d.txt' % NUM_CLASSES\n",
    "with open(LABELS_PATH, 'r') as f:\n",
    "    labels = f.readlines()\n",
    "\n",
    "top5_idx = scores.argsort()[::-1][0:5]\n",
    "\n",
    "for i in top5_idx:\n",
    "    print('(%3f) %s' % (scores[i], labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
